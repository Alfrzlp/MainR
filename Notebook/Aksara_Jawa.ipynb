{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0eo6HXwyU7q"
   },
   "source": [
    "## **Install Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RhyXGLujpiEM"
   },
   "outputs": [],
   "source": [
    "install.packages(\"keras\")\n",
    "install.packages(\"foreach\")\n",
    "install.packages(\"doSNOW\")\n",
    "install.packages(\"googledrive\")\n",
    "install.packages(\"abind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "id": "7avSYA34pnj6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'keras' was built under R version 4.0.3\"\n",
      "-- \u001b[1mAttaching packages\u001b[22m ------------------------------------------------------------------------------- tidyverse 1.3.0 --\n",
      "\n",
      "\u001b[32mv\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.2     \u001b[32mv\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32mv\u001b[39m \u001b[34mtibble \u001b[39m 3.0.4     \u001b[32mv\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.2\n",
      "\u001b[32mv\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.2     \u001b[32mv\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32mv\u001b[39m \u001b[34mreadr  \u001b[39m 1.4.0     \u001b[32mv\u001b[39m \u001b[34mforcats\u001b[39m 0.5.0\n",
      "\n",
      "Warning message:\n",
      "\"package 'tibble' was built under R version 4.0.3\"\n",
      "Warning message:\n",
      "\"package 'tidyr' was built under R version 4.0.3\"\n",
      "Warning message:\n",
      "\"package 'readr' was built under R version 4.0.3\"\n",
      "Warning message:\n",
      "\"package 'dplyr' was built under R version 4.0.3\"\n",
      "-- \u001b[1mConflicts\u001b[22m ---------------------------------------------------------------------------------- tidyverse_conflicts() --\n",
      "\u001b[31mx\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31mx\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "Warning message:\n",
      "\"package 'foreach' was built under R version 4.0.3\"\n",
      "\n",
      "Attaching package: 'foreach'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:purrr':\n",
      "\n",
      "    accumulate, when\n",
      "\n",
      "\n",
      "Warning message:\n",
      "\"package 'doSNOW' was built under R version 4.0.3\"\n",
      "Loading required package: iterators\n",
      "\n",
      "Warning message:\n",
      "\"package 'iterators' was built under R version 4.0.3\"\n",
      "Loading required package: snow\n",
      "\n",
      "Warning message:\n",
      "\"package 'snow' was built under R version 4.0.3\"\n"
     ]
    }
   ],
   "source": [
    "library(keras)\n",
    "library(tidyverse)\n",
    "library(foreach)\n",
    "library(purrr)\n",
    "library(doSNOW) # untuk melakukan iterasi secara paralel\n",
    "library(abind) # untuk bind array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqNNtSSSwUe3"
   },
   "source": [
    "## **Fungsi Untuk Membaca Image dan menjadikan array**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jq6hTBmgo85e"
   },
   "source": [
    "Dengan Pararel iterasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5rfU_tg-pyaD"
   },
   "outputs": [],
   "source": [
    "image_from_directory <- function(alamat, w, h, grayscale = T, ...){\n",
    "  dir = list.files(alamat, full.names = T)\n",
    "  allloc = c()\n",
    "  \n",
    "  # mendapatkan semua lokasi gambar\n",
    "  if(str_detect(dir[1], \"(png|jpg|jpeg)\")) allloc = dir\n",
    "  else{\n",
    "    for(i in 1:length(dir)){\n",
    "      allloc = c(allloc, list.files(dir[i], full.names = T, recursive = T))\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # agar tidak over gunakan core - 1\n",
    "  cores = parallel::detectCores()\n",
    "  cl <- makeSOCKcluster(cores-1)\n",
    "  registerDoSNOW(cl)\n",
    "\n",
    "  # iterasi secara pararel\n",
    "  hasil <- \n",
    "    foreach::foreach(i = 1:length(allloc), .packages = c(\"keras\", \"stringr\"), ...) %dopar% {\n",
    "                     label = str_split(allloc[i], pattern = \"/\")[[1]]\n",
    "                     label = label[length(label)-1]\n",
    "                     \n",
    "                     img = image_load(allloc[i], target_size = c(w, h), grayscale = grayscale)\n",
    "                     img = image_to_array(img)\n",
    "                     img = array_reshape(img, c(1, dim(img)))\n",
    "                     img = img/255\n",
    " \n",
    "                     list(image = img, lab = label)\n",
    "                   }\n",
    "  stopCluster(cl)\n",
    "  # membuat fungsi abind1\n",
    "  abind1 = function(...) abind::abind(..., along = 1)\n",
    "  hasil <- list(image = do.call(abind1, map(hasil, \"image\")),\n",
    "                label = do.call(c, map(hasil, \"lab\")))\n",
    "  \n",
    "  return(hasil)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_from_directory <- function(alamat, w, h, grayscale = T){\n",
    "  dir = list.files(alamat)\n",
    "  allloc = c(); label = c()\n",
    "  \n",
    "  # mendapatkan semua lokasi gambar\n",
    "  if(str_detect(dir[1], \"(png|jpg|jpeg)\")) allloc = dir\n",
    "  else{\n",
    "    for(i in 1:length(dir)){\n",
    "      isi = list.files(paste0(alamat,\"/\",dir[i]), full.names = T, recursive = T)\n",
    "      allloc = c(allloc, isi)\n",
    "      label = c(label, rep(dir[i], length(isi)))\n",
    "    }\n",
    "  }\n",
    "  # make progress bar\n",
    "  pb <- txtProgressBar(1, length(allloc), style = 3)\n",
    "  \n",
    "  images = lapply(allloc, readImage) \n",
    "  for (i in 1:length(allloc)){\n",
    "    images[[i]] <- resize(images[[i]], w, h)\n",
    "    images[[i]] <- toRGB(images[[i]])\n",
    "    setTxtProgressBar(pb, i)\n",
    "  }\n",
    "  close(pb)\n",
    "  \n",
    "  # gabung semua image\n",
    "  cat(\"combine images\")\n",
    "  images = combine(images)\n",
    "  # ubah urutan dimensi \n",
    "  cat(\"\\nubah urutan dimensi\") \n",
    "  images = aperm(images, c(4, 1, 2, 3))\n",
    "  cat(\"\\nDone\") \n",
    "  return(list(images, label))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6-oOMBC5xQZ"
   },
   "source": [
    "# **Untuk Google Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "IWCmcGxOr6ym"
   },
   "outputs": [],
   "source": [
    "library(\"googledrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVLjAqweuYfT"
   },
   "outputs": [],
   "source": [
    "# Check if is running in Colab and redefine is_interactive()\n",
    "if (file.exists(\"/usr/local/lib/python3.6/dist-packages/google/colab/_ipython.py\")) {\n",
    "  install.packages(\"R.utils\")\n",
    "  library(\"R.utils\")\n",
    "  library(\"httr\")\n",
    "  my_check <- function() {return(TRUE)}\n",
    "  reassignInPackage(\"is_interactive\", pkgName = \"httr\", my_check) \n",
    "  options(rlang_interactive=TRUE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8MyYVKrZtAZg"
   },
   "outputs": [],
   "source": [
    "# authorize google drive\n",
    "drive_auth(\n",
    "  email = gargle::gargle_oauth_email(),\n",
    "  path = NULL,\n",
    "  scopes = \"https://www.googleapis.com/auth/drive\",\n",
    "  cache = gargle::gargle_oauth_cache(),\n",
    "  use_oob = gargle::gargle_oob_default(),\n",
    "  token = NULL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BuJ8LeOs1VeT"
   },
   "outputs": [],
   "source": [
    "drive_download(\"Aksara Jawa/train/ba/ba.0.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8-Tv3LHBDqS"
   },
   "source": [
    "# **Import gambar**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCkiPXaZw1lO"
   },
   "source": [
    "Masukkan file zip dulu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Nuxev_2EZljl"
   },
   "outputs": [],
   "source": [
    "# unzip data\n",
    "unzip(\"/content/Aksara Jawa.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "yAV0tWnKqKrn"
   },
   "outputs": [],
   "source": [
    "w = 100\n",
    "h = 100\n",
    "\n",
    "path = \"/content/Aksara Jawa/train\"\n",
    "train = image_from_directory(path, w, h, grayscale = T)\n",
    "x_train = train[[1]] \n",
    "y_train = train[[2]] \n",
    "y_train = factor(y_train, labels = 0:19)\n",
    "\n",
    "path2 = \"/content/Aksara Jawa/test\"\n",
    "test = image_from_directory(path2, w, h, grayscale = T)\n",
    "x_test = test[[1]] \n",
    "y_test = test[[2]] \n",
    "y_test = factor(y_test, labels = 0:19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5OncMVenaxjN"
   },
   "source": [
    "# **Cek Dimensi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "NBTqT_DDasE7",
    "outputId": "ac076279-6127-444e-a9c3-bf2a83bf2c8f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>2520</li><li>100</li><li>100</li><li>1</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2520\n",
       "\\item 100\n",
       "\\item 100\n",
       "\\item 1\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2520\n",
       "2. 100\n",
       "3. 100\n",
       "4. 1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 2520  100  100    1"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>620</li><li>100</li><li>100</li><li>1</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 620\n",
       "\\item 100\n",
       "\\item 100\n",
       "\\item 1\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 620\n",
       "2. 100\n",
       "3. 100\n",
       "4. 1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 620 100 100   1"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>2520</li><li>20</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2520\n",
       "\\item 20\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2520\n",
       "2. 20\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 2520   20"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>620</li><li>20</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 620\n",
       "\\item 20\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 620\n",
       "2. 20\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 620  20"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(x_train)\n",
    "dim(x_test)\n",
    "\n",
    "# ubah dimensi label\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "dim(y_train)\n",
    "dim(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNtyIkeXa7fl"
   },
   "source": [
    "# **Membuat Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "mBO9MoQua6Ux",
    "outputId": "6bb062cc-cec6-4d03-8616-636ab5347d40"
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in normalize_shape(input_shape): object 'w' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in normalize_shape(input_shape): object 'w' not found\nTraceback:\n",
      "1. keras_model_sequential() %>% layer_conv_2d(filters = 32, kernel_size = 3, \n .     padding = \"same\", input_shape = c(w, h, 1), activation = \"relu\") %>% \n .     layer_conv_2d(filters = 32, kernel_size = 3, padding = \"same\", \n .         activation = \"relu\") %>% layer_max_pooling_2d(pool_size = 2) %>% \n .     layer_conv_2d(filters = 64, kernel_size = 3, padding = \"same\", \n .         activation = \"relu\") %>% layer_conv_2d(filters = 64, \n .     kernel_size = 3, padding = \"same\", activation = \"relu\") %>% \n .     layer_max_pooling_2d(pool_size = 2) %>% layer_conv_2d(filters = 128, \n .     kernel_size = 3, padding = \"same\", activation = \"relu\") %>% \n .     layer_conv_2d(filters = 128, kernel_size = 3, padding = \"same\", \n .         activation = \"relu\") %>% layer_max_pooling_2d(pool_size = 2) %>% \n .     layer_flatten() %>% layer_dense(32, activation = \"relu\") %>% \n .     layer_dropout(0.5) %>% layer_dense(20, activation = \"softmax\")",
      "2. layer_dense(., 20, activation = \"softmax\")",
      "3. create_layer(keras$layers$Dense, object, list(units = as.integer(units), \n .     activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n .     bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n .     bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n .     kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n .     batch_size = as_nullable_integer(batch_size), dtype = dtype, \n .     name = name, trainable = trainable, weights = weights))",
      "4. layer_dropout(., 0.5)",
      "5. create_layer(keras$layers$Dropout, object, list(rate = rate, \n .     noise_shape = normalize_shape(noise_shape), seed = seed, \n .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n .     batch_size = as_nullable_integer(batch_size), name = name, \n .     trainable = trainable, weights = weights))",
      "6. layer_dense(., 32, activation = \"relu\")",
      "7. create_layer(keras$layers$Dense, object, list(units = as.integer(units), \n .     activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n .     bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n .     bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n .     kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n .     batch_size = as_nullable_integer(batch_size), dtype = dtype, \n .     name = name, trainable = trainable, weights = weights))",
      "8. layer_flatten(.)",
      "9. create_layer(keras$layers$Flatten, object, args)",
      "10. layer_max_pooling_2d(., pool_size = 2)",
      "11. create_layer(keras$layers$MaxPooling2D, object, list(pool_size = as.integer(pool_size), \n  .     strides = as_nullable_integer(strides), padding = padding, \n  .     data_format = data_format, batch_size = as_nullable_integer(batch_size), \n  .     name = name, trainable = trainable, weights = weights))",
      "12. layer_conv_2d(., filters = 128, kernel_size = 3, padding = \"same\", \n  .     activation = \"relu\")",
      "13. create_layer(keras$layers$Conv2D, object, list(filters = as.integer(filters), \n  .     kernel_size = as_integer_tuple(kernel_size), strides = as_integer_tuple(strides), \n  .     padding = padding, data_format = data_format, dilation_rate = as_integer_tuple(dilation_rate), \n  .     activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n  .     bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n  .     bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n  .     kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n  .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n  .     batch_size = as_nullable_integer(batch_size), dtype = dtype, \n  .     name = name, trainable = trainable, weights = weights))",
      "14. layer_conv_2d(., filters = 128, kernel_size = 3, padding = \"same\", \n  .     activation = \"relu\")",
      "15. create_layer(keras$layers$Conv2D, object, list(filters = as.integer(filters), \n  .     kernel_size = as_integer_tuple(kernel_size), strides = as_integer_tuple(strides), \n  .     padding = padding, data_format = data_format, dilation_rate = as_integer_tuple(dilation_rate), \n  .     activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n  .     bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n  .     bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n  .     kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n  .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n  .     batch_size = as_nullable_integer(batch_size), dtype = dtype, \n  .     name = name, trainable = trainable, weights = weights))",
      "16. layer_max_pooling_2d(., pool_size = 2)",
      "17. create_layer(keras$layers$MaxPooling2D, object, list(pool_size = as.integer(pool_size), \n  .     strides = as_nullable_integer(strides), padding = padding, \n  .     data_format = data_format, batch_size = as_nullable_integer(batch_size), \n  .     name = name, trainable = trainable, weights = weights))",
      "18. layer_conv_2d(., filters = 64, kernel_size = 3, padding = \"same\", \n  .     activation = \"relu\")",
      "19. create_layer(keras$layers$Conv2D, object, list(filters = as.integer(filters), \n  .     kernel_size = as_integer_tuple(kernel_size), strides = as_integer_tuple(strides), \n  .     padding = padding, data_format = data_format, dilation_rate = as_integer_tuple(dilation_rate), \n  .     activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n  .     bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n  .     bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n  .     kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n  .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n  .     batch_size = as_nullable_integer(batch_size), dtype = dtype, \n  .     name = name, trainable = trainable, weights = weights))",
      "20. layer_conv_2d(., filters = 64, kernel_size = 3, padding = \"same\", \n  .     activation = \"relu\")",
      "21. create_layer(keras$layers$Conv2D, object, list(filters = as.integer(filters), \n  .     kernel_size = as_integer_tuple(kernel_size), strides = as_integer_tuple(strides), \n  .     padding = padding, data_format = data_format, dilation_rate = as_integer_tuple(dilation_rate), \n  .     activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n  .     bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n  .     bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n  .     kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n  .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n  .     batch_size = as_nullable_integer(batch_size), dtype = dtype, \n  .     name = name, trainable = trainable, weights = weights))",
      "22. layer_max_pooling_2d(., pool_size = 2)",
      "23. create_layer(keras$layers$MaxPooling2D, object, list(pool_size = as.integer(pool_size), \n  .     strides = as_nullable_integer(strides), padding = padding, \n  .     data_format = data_format, batch_size = as_nullable_integer(batch_size), \n  .     name = name, trainable = trainable, weights = weights))",
      "24. layer_conv_2d(., filters = 32, kernel_size = 3, padding = \"same\", \n  .     activation = \"relu\")",
      "25. create_layer(keras$layers$Conv2D, object, list(filters = as.integer(filters), \n  .     kernel_size = as_integer_tuple(kernel_size), strides = as_integer_tuple(strides), \n  .     padding = padding, data_format = data_format, dilation_rate = as_integer_tuple(dilation_rate), \n  .     activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n  .     bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n  .     bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n  .     kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n  .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n  .     batch_size = as_nullable_integer(batch_size), dtype = dtype, \n  .     name = name, trainable = trainable, weights = weights))",
      "26. layer_conv_2d(., filters = 32, kernel_size = 3, padding = \"same\", \n  .     input_shape = c(w, h, 1), activation = \"relu\")",
      "27. create_layer(keras$layers$Conv2D, object, list(filters = as.integer(filters), \n  .     kernel_size = as_integer_tuple(kernel_size), strides = as_integer_tuple(strides), \n  .     padding = padding, data_format = data_format, dilation_rate = as_integer_tuple(dilation_rate), \n  .     activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n  .     bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n  .     bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n  .     kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n  .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n  .     batch_size = as_nullable_integer(batch_size), dtype = dtype, \n  .     name = name, trainable = trainable, weights = weights))",
      "28. normalize_shape(input_shape)"
     ]
    }
   ],
   "source": [
    "model <- keras_model_sequential() %>% \n",
    "  layer_conv_2d(filters = 32, kernel_size = 3,\n",
    "                padding = \"same\", input_shape = c(w, h, 1), activation = \"relu\") %>% \n",
    "  layer_conv_2d(filters = 32, kernel_size = 3,\n",
    "                padding = \"same\", activation = \"relu\") %>% \n",
    "  layer_max_pooling_2d(pool_size = 2) %>% \n",
    "  \n",
    "  layer_conv_2d(filters = 64, kernel_size = 3,\n",
    "                padding = \"same\", activation = \"relu\") %>% \n",
    "  layer_conv_2d(filters = 64, kernel_size = 3,\n",
    "                padding = \"same\", activation = \"relu\") %>% \n",
    "  layer_max_pooling_2d(pool_size = 2) %>% \n",
    "  \n",
    "  layer_conv_2d(filters = 128, kernel_size = 3,\n",
    "                padding = \"same\", activation = \"relu\") %>% \n",
    "  layer_conv_2d(filters = 128, kernel_size = 3,\n",
    "                padding = \"same\", activation = \"relu\") %>% \n",
    "  layer_max_pooling_2d(pool_size = 2) %>%\n",
    "\n",
    "  layer_flatten() %>%\n",
    "  layer_dense(32, activation = \"relu\") %>%\n",
    "  layer_dropout(0.5) %>% \n",
    "  \n",
    "  layer_dense(20, activation = \"softmax\")\n",
    "\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-rfhXfTjbYs"
   },
   "source": [
    "# **Compile**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "gIe0LMYqbKrm"
   },
   "outputs": [],
   "source": [
    "# compile\n",
    "model %>% compile(\n",
    "  loss = \"categorical_crossentropy\",\n",
    "  optimizer = optimizer_rmsprop(),\n",
    "  metrics = \"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eDbngF9bd8G"
   },
   "source": [
    "# **Fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "WzJEzXk1bN12"
   },
   "outputs": [],
   "source": [
    "history <- model %>%\n",
    "  fit(x_train,\n",
    "      y_train,\n",
    "      batch_size = 30,\n",
    "      epoch = 70,\n",
    "      verbose = 1\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "KNNAC6YSboYx",
    "outputId": "e98677d5-a67d-46ce-b9ee-968d85e02344"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Final epoch (plot to see history):\n",
       "    loss: 0.09934\n",
       "accuracy: 0.9639 "
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>loss</dt><dd>0.852081775665283</dd><dt>accuracy</dt><dd>0.861290335655212</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[loss] 0.852081775665283\n",
       "\\item[accuracy] 0.861290335655212\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "loss\n",
       ":   0.852081775665283accuracy\n",
       ":   0.861290335655212\n",
       "\n"
      ],
      "text/plain": [
       "     loss  accuracy \n",
       "0.8520818 0.8612903 "
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history\n",
    "# plot(history)\n",
    "\n",
    "model %>% evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UTOtK8M06N_"
   },
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "2dHlUrfY0As3"
   },
   "outputs": [],
   "source": [
    "save_model_hdf5(model, \"model_aksara_jawa100_4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "A1CmbVPb9Pfo"
   },
   "outputs": [],
   "source": [
    "model <- load_model_hdf5(\"/content/model_aksara_jawa100_4.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vlsVnnVb9eA"
   },
   "source": [
    "# **Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "waZfC48tbsHE",
    "outputId": "d79b1911-c203-4a68-9bc7-3ff81fa1c49f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        actual\n",
       "prediksi ba ca da dha ga ha ja ka la ma na nga nya pa ra sa ta tha wa ya\n",
       "      0  28  0  0   0  0  0  0  0  0  0  0   2   2  0  0  0  0   3  2  0\n",
       "      1   0 26  0   0  0  0  0  0  0  0  0   0   0  0  0  2  0   0  0  0\n",
       "      2   0  0 31   0  0  0  0  0  0  0  0   0   0  0  0  0  0   0  0  0\n",
       "      3   0  0  0  28  0  0  0  0  0  0  0   0   0  4  0  0  0   0  1  0\n",
       "      4   0  0  0   0 28  0  0  0  0  0  0   0   0  0  0  0  0   0  0  0\n",
       "      5   2  0  0   0  0 29  0  0  0  0  0   0   0  0  0  0  6   0  0  0\n",
       "      6   0  0  0   0  0  0 31  0  0  0  0   0   0  0  0  0  0   0  0  0\n",
       "      7   0  0  0   2  0  1  0 31  0  0  0   1   0  0  0  0  1   0  0  0\n",
       "      8   0  0  0   0  0  0  0  0 31  0  0   0   0  1  0  0  0   0  0  1\n",
       "      9   0  0  0   0  0  0  0  0  0 31  0   0   0  0  0  0  0   0  0  0\n",
       "      10  0  0  0   0  0  0  0  0  0  0 31   0   0  0  0  0  0   0  0  0\n",
       "      11  0  0  0   0  0  0  0  0  0  0  0  28   0  0  0  0  0   7  3  0\n",
       "      12  1  0  0   0  0  0  0  0  0  0  0   0  29  0  0  0  0   0  0  0\n",
       "      13  0  0  0   0  0  1  0  0  0  0  0   0   0 25  0  0  0   0  0  0\n",
       "      14  0  0  0   0  3  0  0  0  0  0  0   0   0  0 31  0  0   0  0  0\n",
       "      15  0  5  0   1  0  0  0  0  0  0  0   0   0  1  0 29  0   0  0  0\n",
       "      16  0  0  0   0  0  0  0  0  0  0  0   0   0  0  0  0 24   0  0  0\n",
       "      17  0  0  0   0  0  0  0  0  0  0  0   0   0  0  0  0  0  21  0  0\n",
       "      18  0  0  0   0  0  0  0  0  0  0  0   0   0  0  0  0  0   0 25  0\n",
       "      19  0  0  0   0  0  0  0  0  0  0  0   0   0  0  0  0  0   0  0 30"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hasil = model %>% predict_classes(x_test)\n",
    "actual = test[[2]] \n",
    "\n",
    "table(prediksi = hasil, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eBxROntcjp1s"
   },
   "outputs": [],
   "source": [
    "# Dengan ggplot2\n",
    "table(prediksi = hasil, actual) %>% \n",
    "  as.data.frame() %>% \n",
    "  ggplot()+\n",
    "  geom_tile(aes(x = actual, y = prediksi, fill = Freq))+\n",
    "  geom_text(aes(x = actual, y = prediksi, label = Freq), col = \"white\")+\n",
    "  theme(legend.position = \"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fbHZ0OL_kac"
   },
   "source": [
    "# **Prediksi Beberapa Gambar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "zgkIItVh_3V_"
   },
   "outputs": [],
   "source": [
    "aksara = c(\"ba\" ,\"ca\" ,\"da\" ,\"dha\",\"ga\" ,\"ha\" ,\"ja\" ,\"ka\" ,\n",
    "           \"la\" ,\"ma\" ,\"na\" ,\"nga\", \"nya\" ,\"pa\" ,\"ra\" ,\"sa\" ,\n",
    "           \"ta\" ,\"tha\" ,\"wa\" ,\"ya\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "4BtYn_k1_jrn",
    "outputId": "7adf5b67-7166-485a-e986-032458bb419e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'na1.png'"
      ],
      "text/latex": [
       "'na1.png'"
      ],
      "text/markdown": [
       "'na1.png'"
      ],
      "text/plain": [
       "[1] \"na1.png\""
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>25</li><li>100</li><li>100</li><li>1</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 25\n",
       "\\item 100\n",
       "\\item 100\n",
       "\\item 1\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 25\n",
       "2. 100\n",
       "3. 100\n",
       "4. 1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  25 100 100   1"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>3</li><li>100</li><li>100</li><li>1</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 3\n",
       "\\item 100\n",
       "\\item 100\n",
       "\\item 1\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 3\n",
       "2. 100\n",
       "3. 100\n",
       "4. 1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]   3 100 100   1"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ambil nama file gambar\n",
    "img = list.files(\"/content/Aksara Jawa/predict\")\n",
    "\n",
    "# ambil array gambar\n",
    "gambar = image_from_directory(\"/content/Aksara Jawa/predict\", w, h, grayscale = T)\n",
    "gambar = gambar[[1]]\n",
    "dim(gambar)\n",
    "\n",
    "# cara subset array\n",
    "dim(gambar[1:3, , , ,drop = F])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "cB6xesCjBHTg",
    "outputId": "2bc0060a-2d72-4560-9483-1a6fc7f58594"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Nama Gambar\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "'ba17.png'"
      ],
      "text/latex": [
       "'ba17.png'"
      ],
      "text/markdown": [
       "'ba17.png'"
      ],
      "text/plain": [
       "[1] \"ba17.png\""
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"prediksi\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "'wa'"
      ],
      "text/latex": [
       "'wa'"
      ],
      "text/markdown": [
       "'wa'"
      ],
      "text/plain": [
       "[1] \"wa\""
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "indeks = 1\n",
    "\n",
    "# aslinya\n",
    "print(\"Nama Gambar\")\n",
    "img[indeks]\n",
    "\n",
    "\n",
    "#output predict clasess 0-19\n",
    "print(\"prediksi\")\n",
    "model %>% predict_classes(gambar[indeks, , , ,drop = F]) %>% +1 %>% aksara[.]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Aksara Jawa.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
