clean_names() %>%
mutate_at(
vars(rad, river_flg), ~ as.factor(.x)
)
glimpse(df_train)
glimpse(df_test)
# Model awal --------------------------------------------------------------
m1 <- lm(medv ~ (.)^2 , data = df_train)
m1 <- stats::step(m1, trace = F)
summary(m1)
preds <- predict(m1, newdata = df_test)
unique(df_train$rad)
unique(df_train$river_flg)
source("~/.active-rstudio-document", echo=TRUE)
unique(df_test$rad)
unique(df_test$rad)
unique(df_train$rad)
df_train <- read.csv(str_glue('{loc}/DHP_Train_Revised.csv')) %>%
clean_names() %>%
mutate_at(
vars(river_flg), ~ as.factor(.x)
)
df_test <- read.csv(str_glue('{loc}/DHP_Test.csv')) %>%
clean_names() %>%
rename(tax = tax_01) %>%
mutate_at(
vars(river_flg), ~ as.factor(.x)
)
df_sub <- read.csv(str_glue('{loc}/DHP_Sample.csv'))
glimpse(df_train)
glimpse(df_test)
glimpse(df_sub)
# Model awal --------------------------------------------------------------
m1 <- lm(medv ~ (.)^2 , data = df_train)
m1 <- stats::step(m1, trace = F)
summary(m1)
preds <- predict(m1, newdata = df_test)
# Train test split ---------------------------------------------------------
set.seed(1)
splits <- initial_split(df_train, prop = 0.8)
splits
train_set <- training(splits)
test_set  <- testing(splits)
set.seed(1)
val_set <- validation_split(
train_set,
prop = 0.7
)
val_set
# Advance Model -----------------------------------------------------------
model_spec <-
rand_forest(mtry = tune(), min_n = tune()) %>%
set_engine('ranger', num.threads = 4) %>%
set_mode('regression')
# Workflow ----------------------------------------------------------------
my_recipe <-
recipe(medv ~ ., data = train_set) %>%
# update_role(Id, new_role = "id") %>%
step_YeoJohnson(all_numeric_predictors())
my_recipe %>% summary()
my_workflow <-
workflow() %>%
add_model(model_spec) %>%
add_recipe(my_recipe)
# Training ----------------------------------------------------------------
model_res <-
my_workflow %>%
tune_grid(
val_set,
grid = 50,
control = control_grid(save_pred = TRUE, verbose = T, allow_par = T),
metrics = reg_metric
)
model_res %>%
collect_metrics() %>%
filter(.metric == 'rmse') %>%
arrange(mean) %>%
select(mean)
model_res %>%
collect_metrics() %>%
pivot_wider(names_from = .metric, values_from = mean) %>%
arrange(rmse, desc(rsq))
rmse(df_train, truth = medv, estimate = predict(m1, newdata = df_train))
preds <- predict(m1, newdata = df_test)
# Submission --------------------------------------------------------------
hasil <- df_sub %>%
mutate(MEDV = preds)
write.csv(hasil, 'D:/__Datasets/sub.csv', row.names = F, quote = F)
system(
'kaggle competitions submit -c delhihousepriceprediction -f D:/__Datasets/sub.csv -m "Message"'
)
# Model terbaik -----------------------------------------------------------
best_model <- model_res %>%
select_best(metric = 'rmse')
final_wf <- my_workflow %>%
finalize_workflow(best_model)
final_wf
# fit terakhir
final_fit <- final_wf %>% fit(df_train)
final_fit
# Evaluasi ----------------------------------------------------------------
df_train %>%
bind_cols(predict(final_fit, .)) %>%
reg_metric(truth = score, estimate = .pred)
# Evaluasi ----------------------------------------------------------------
df_train %>%
bind_cols(predict(final_fit, .)) %>%
reg_metric(truth = medv, estimate = .pred)
test_set %>%
bind_cols(predict(final_fit, .)) %>%
reg_metric(truth = medv, estimate = .pred)
# Prediksi ----------------------------------------------------------------
preds <- predict(final_fit, new_data = df_test) %>% pull()
preds
hasil <- df_test %>%
bind_cols(predict(final_fit, new_data = .)) %>%
select(Id, Expected = .pred)
df_test
hasil <- df_test %>%
bind_cols(predict(final_fit, new_data = .)) %>%
select(Id = id, MEDV = .pred)
hasil
write.csv(hasil, 'D:/__Datasets/sub.csv', row.names = F, quote = F)
system(
'kaggle competitions submit -c delhihousepriceprediction -f D:/__Datasets/sub.csv -m "Message"'
)
ggplot(df_train, aes(x = medv)) +
geom_histogram(bins = 30, col = "white")
ggplot(df_train, aes(x = medv)) +
geom_histogram(bins = 30, col = "white") +
scale_x_log10()
df_train <- read.csv(str_glue('{loc}/DHP_Train_Revised.csv')) %>%
clean_names() %>%
mutate(
river_flg = as.factor(river_flg),
medv = log10(medv)
)
df_test <- read.csv(str_glue('{loc}/DHP_Test.csv')) %>%
clean_names() %>%
rename(tax = tax_01) %>%
mutate_at(
vars(river_flg), ~ as.factor(.x)
)
# Train test split ---------------------------------------------------------
set.seed(1)
splits <- initial_split(df_train, prop = 0.8)
splits
train_set <- training(splits)
test_set  <- testing(splits)
set.seed(1)
val_set <- validation_split(
train_set,
prop = 0.7
)
val_set
# Advance Model -----------------------------------------------------------
model_spec <-
rand_forest(mtry = tune(), min_n = tune()) %>%
set_engine('ranger', num.threads = 4) %>%
set_mode('regression')
# Workflow ----------------------------------------------------------------
my_recipe <-
recipe(medv ~ ., data = train_set) %>%
# update_role(Id, new_role = "id") %>%
step_YeoJohnson(all_numeric_predictors())
my_recipe %>% summary()
my_workflow <-
workflow() %>%
add_model(model_spec) %>%
add_recipe(my_recipe)
# Training ----------------------------------------------------------------
model_res <-
my_workflow %>%
tune_grid(
val_set,
grid = 150,
control = control_grid(save_pred = TRUE, verbose = T, allow_par = T),
metrics = reg_metric
)
model_res %>%
collect_metrics() %>%
filter(.metric == 'rmse') %>%
arrange(mean) %>%
select(mean)
model_res %>%
collect_metrics() %>%
pivot_wider(names_from = .metric, values_from = mean) %>%
arrange(rmse, desc(rsq))
# Model terbaik -----------------------------------------------------------
best_model <- model_res %>%
select_best(metric = 'rmse')
final_wf <- my_workflow %>%
finalize_workflow(best_model)
final_wf
# fit terakhir
final_fit <- final_wf %>% fit(df_train)
final_fit
# Evaluasi ----------------------------------------------------------------
df_train %>%
bind_cols(predict(final_fit, .)) %>%
reg_metric(truth = medv, estimate = .pred)
test_set %>%
bind_cols(predict(final_fit, .)) %>%
reg_metric(truth = medv, estimate = .pred)
# Prediksi ----------------------------------------------------------------
preds <- predict(final_fit, new_data = df_test) %>% pull()
preds
hasil <- df_test %>%
bind_cols(predict(final_fit, new_data = .)) %>%
select(Id = id, MEDV = .pred)
write.csv(hasil, 'D:/__Datasets/sub.csv', row.names = F, quote = F)
system(
'kaggle competitions submit -c delhihousepriceprediction -f D:/__Datasets/sub.csv -m "Message"'
)
10 ^ log(preds, base = 10)
preds
1 / log10(preds)
preds <- 1 / log10(preds)
df_train$medv[1:5]
# Submission --------------------------------------------------------------
hasil <- df_sub %>%
mutate(MEDV = preds)
write.csv(hasil, 'D:/__Datasets/sub.csv', row.names = F, quote = F)
system(
'kaggle competitions submit -c delhihousepriceprediction -f D:/__Datasets/sub.csv -m "Message"'
)
ggplot(df_train, aes(x = medv)) +
geom_histogram(bins = 30, col = "white") +
scale_x_log()
df_train <- read.csv(str_glue('{loc}/DHP_Train_Revised.csv')) %>%
clean_names() %>%
mutate(
river_flg = as.factor(river_flg)
)
ggplot(df_train, aes(x = exp(medv))) +
geom_histogram(bins = 30, col = "white")
glimpse(df_train)
ggplot(df_train, aes(x = log(medv))) +
geom_histogram(bins = 30, col = "white")
df_train <- read.csv(str_glue('{loc}/DHP_Train_Revised.csv')) %>%
clean_names() %>%
mutate(
river_flg = as.factor(river_flg),
medv = log(medv)
)
df_test <- read.csv(str_glue('{loc}/DHP_Test.csv')) %>%
clean_names() %>%
rename(tax = tax_01) %>%
mutate_at(
vars(river_flg), ~ as.factor(.x)
)
df_sub <- read.csv(str_glue('{loc}/DHP_Sample.csv'))
library(tidyverse)
library(tidymodels)
tidymodels::tidymodels_prefer()
# Data --------------------------------------------------------------------
loc <- 'D:/__Datasets/ml/2022-regression-data-challenge'
df_train <- read.csv(str_glue('{loc}/train.csv'))
df_test <- read.csv(str_glue('{loc}/test.csv'))
df_sub <- read.csv(str_glue('{loc}/submission.csv'))
glimpse(df_train)
glimpse(df_test)
df_train %>%
arrange(Id) %>%
slice(-1)
df_train %>%
arrange(Id) %>%
slice(-1) %>%
{
signal::interp1((.)$Id, (.)$score, df_test$Id,
method = 'pc', extrap = T)
}
dim(df_train)
df_train %>%
arrange(Id) %>%
sample_frac(0.8) %>%
{
signal::interp1((.)$Id, (.)$score, df_test$Id, method = 'pc', extrap = T)
}
df_train %>%
arrange(Id) %>%
slice(-c(1:2)) %>%
{
signal::interp1((.)$Id, (.)$score, df_test$Id, method = 'pc', extrap = T)
}
dim(df_train)
pred <- c()
pred <- c()
signal::interp1(df_train$Id[-i], df_train$score[-i], df_test$Id, method = 'pc', extrap = T)
pred <- c()
message('Proses ke ', i)
pred <- c()
for (i in 1:nrow(df_train)) {
message('Proses ke ', i)
pred <- c(
pred,
signal::interp1(df_train$Id[-i], df_train$score[-i], df_test$Id, method = 'pc', extrap = T)
)
}
nrow(df_train)
nrow(df_train)/10
nrow(df_train)/100
summary(df_train)
ggplot(df_train, aes(x = Id)) +
geom_histogram()
signal::interp1(df_train$Id[-c(2:100)], df_train$score[-c(2:100)], df_test$Id, method = 'pc', extrap = T)
signal::interp1(df_train$Id[-c(1:100)], df_train$score[-c(1:100)], df_test$Id, method = 'pc', extrap = T)
df_train$score[-c(1:100)]
df_train$Id[-c(1:100)]
?signal::interp1
df_train %>%
arrange(Id) %>%
slice(-c(1:2)) %>%
{
signal::interp1((.)$Id, (.)$score, df_test$Id, method = 'pc', extrap = T)
}
preds <- df_train %>%
arrange(Id) %>% {
pracma::pchip((.)$Id, (.)$score, df_test$Id)
}
preds <- df_train %>%
arrange(Id) %>% {
signal::interp1((.)$Id, (.)$score, df_test$Id,
method = 'pc', extrap = T)
}
# -------------------------------------------------------------------------
hasil <- df_sub %>%
mutate(
Expected = preds - 0.3
)
write.csv(hasil, 'D:/__Datasets/sub.csv', row.names = F, quote = F)
system(
'kaggle competitions submit -c 2022-regression-data-challenge -f D:/__Datasets/sub.csv -m "Message"'
)
preds
# Interpolation -----------------------------------------------------------
ggplot(df_train) +
geom_point(aes(x = Id, y = score))
# Interpolation -----------------------------------------------------------
ggplot(df_train) +
geom_point(aes(y = Id, x = score))
ggplot(hasil) +
geom_point(aes(y = Id, x = Expected))
df_test$Id
preds <- df_train %>%
arrange(Id) %>% {
signal::interp1((.)$Id, (.)$score, df_test$Id - 1,
method = 'pc', extrap = T)
}
preds
# -------------------------------------------------------------------------
hasil <- df_sub %>%
mutate(
Expected = preds
)
write.csv(hasil, 'D:/__Datasets/sub.csv', row.names = F, quote = F)
system(
'kaggle competitions submit -c 2022-regression-data-challenge -f D:/__Datasets/sub.csv -m "Message"'
)
preds <- df_train %>%
arrange(Id) %>% {
signal::interp1((.)$Id, (.)$score, df_test$Id,
method = 'pc', extrap = T)
}
preds <- df_train %>%
arrange(Id) %>% {
signal::interp1((.)$Id, (.)$score, df_test$Id,
method = 'pc', extrap = T)
}
round(preds)
round(preds, 3)
signal::interp1((.)$Id, (.)$score, df_test$Id,
method = 'pc', extrap = F)
preds <- df_train %>%
arrange(Id) %>% {
signal::interp1((.)$Id, (.)$score, df_test$Id,
method = 'pc', extrap = F)
}
preds
# -------------------------------------------------------------------------
hasil <- df_sub %>%
mutate(
Expected = round(preds, 3)
)
hasil %>% is.na() %>% colSums()
hasil %>% filter(is.na(Expected))
write.csv(hasil, 'D:/__Datasets/sub.csv', row.names = F, quote = F)
system(
'kaggle competitions submit -c 2022-regression-data-challenge -f D:/__Datasets/sub.csv -m "Message"'
)
preds <- df_train %>%
arrange(Id) %>% {
signal::interp1((.)$Id, (.)$score, df_test$Id,
method = 'pc', extrap = T)
}
# -------------------------------------------------------------------------
hasil <- df_sub %>%
mutate(
Expected = round(preds - 0.111, 3)
)
write.csv(hasil, 'D:/__Datasets/sub.csv', row.names = F, quote = F)
system(
'kaggle competitions submit -c 2022-regression-data-challenge -f D:/__Datasets/sub.csv -m "Message"'
)
# -------------------------------------------------------------------------
hasil <- df_sub %>%
mutate(
Expected = round(preds - 1.111, 3)
)
write.csv(hasil, 'D:/__Datasets/sub.csv', row.names = F, quote = F)
system(
'kaggle competitions submit -c 2022-regression-data-challenge -f D:/__Datasets/sub.csv -m "Message"'
)
pak::pak('finetune')
'+'  <- function(x, y) {
as.numeric(paste0(x, y))
}
10 + 0
10 + 0
library(tidymodels)
tidymodels_prefer()
svm_rec <-
recipe(class ~ ., data = cells) %>%
step_YeoJohnson(all_numeric_predictors()) %>%
step_normalize(all_numeric_predictors())
svm_spec <-
svm_rbf(cost = tune(), rbf_sigma = tune()) %>%
set_engine("kernlab") %>%
set_mode("classification")
svm_wflow <-
workflow() %>%
add_model(svm_spec) %>%
add_recipe(svm_rec)
cost()
rbf_sigma()
svm_param <-
svm_wflow %>%
extract_parameter_set_dials() %>%
update(rbf_sigma = rbf_sigma(c(-7, -1)))
svm_param
'+'  <- function(x, y) {
as.numeric(paste0(x, y))
}
1 + 1
'+'  <- function(x, y) {
as.numeric(x + y)
}
1 + 1
as.numeric(x + y + 1)
'+'  <- function(x, y) {
as.numeric(x + y + 1)
}
1 + 1
'+'  <- function(x, y) {
x + y + 1
}
1 + 1
'+'  <- function(x, y) {
3
}
1 + 1
2 + 3
4 + 5
log10(c(1e-100, Inf))
set.seed(1401)
start_grid <-
svm_param %>%
update(
cost = cost(c(-6, 1)),
rbf_sigma = rbf_sigma(c(-6, -4))
) %>%
grid_regular(levels = 2)
set.seed(1402)
svm_initial <-
svm_wflow %>%
tune_grid(
resamples = cell_folds,
grid = start_grid,
metrics = roc_res)
svm_param
svm_param %>%
update(
cost = cost(c(-6, 1)),
rbf_sigma = rbf_sigma(c(-6, -4))
)
svm_param %>%
update(
cost = cost(c(-6, 1)),
rbf_sigma = rbf_sigma(c(-6, -4))
) %>%
extract_parameter_set_dials()
svm_param %>%
update(
cost = cost(c(-6, 1)),
rbf_sigma = rbf_sigma(c(-6, -4))
) %>%
grid_regular(levels = 2)
svm_param %>% grid_regular(2)
svm_param %>% grid_regular(levels = 2)
collect_metrics(svm_initial)
ctrl <- control_bayes(verbose = TRUE)
set.seed(1403)
svm_bo <-
svm_wflow %>%
tune_bayes(
resamples = cell_folds,
metrics = roc_res,
initial = svm_initial,
param_info = svm_param,
iter = 25,
control = ctrl
)
